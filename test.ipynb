{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "from datetime import date, timedelta\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, encoder_len: int, decoder_len: int, targets: list, reals=None,\n",
    "                 categoricals=None, time_var=None):\n",
    "        self.df = df\n",
    "        self.encoder_len = encoder_len\n",
    "        self.decoder_len = decoder_len\n",
    "        self.targets = targets\n",
    "        self.reals = reals\n",
    "        self.categoricals = categoricals\n",
    "        self.time_var = time_var\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        \"\"\"\n",
    "        Get data window of  size = decoder + encoder length from the given element index\n",
    "        :param idx:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        def get_window(idx_start: int, idx_end: int):\n",
    "\n",
    "            \"\"\"\n",
    "            Get data window of  size = decoder + encoder length\n",
    "            :param self:\n",
    "            :param idx_start: index of the first element in the window\n",
    "            :param idx_end: index of the last element in the window\n",
    "            :return:\n",
    "            \"\"\"\n",
    "\n",
    "            tensor_arr = []\n",
    "\n",
    "            targets_tensor = torch.Tensor(size=(self.encoder_len + self.decoder_len, len(self.targets)))\n",
    "            targets_tensor[:, :] = torch.from_numpy(self.df.iloc[idx_start: idx_end][self.targets].values).to(targets_tensor)\n",
    "            tensor_arr.append(targets_tensor)\n",
    "\n",
    "            if self.reals:\n",
    "                conts_tensor = torch.Tensor(size=(self.encoder_len + self.decoder_len, len(self.reals)))\n",
    "                conts_tensor[:, :] = torch.from_numpy(self.df.iloc[idx_start: idx_end][self.reals].values).to(conts_tensor)\n",
    "                tensor_arr.append(conts_tensor)\n",
    "\n",
    "            if self.categoricals:\n",
    "                cats_tensor = torch.Tensor(size=(self.encoder_len + self.decoder_len, len(self.categoricals)))\n",
    "                cats_tensor[:, :] = torch.from_numpy(self.df.iloc[idx_start: idx_end][self.categoricals].values).to(cats_tensor)\n",
    "                tensor_arr.append(cats_tensor)\n",
    "\n",
    "            window = torch.cat(tensor_arr, 1)\n",
    "\n",
    "            return window\n",
    "\n",
    "        last_data_element_idx = self.df.shape[0] - 1\n",
    "        window_size = self.encoder_len + self.decoder_len\n",
    "        begin_idx = idx - self.encoder_len\n",
    "        end_idx = idx + self.decoder_len\n",
    "\n",
    "        if begin_idx < 0:\n",
    "            # return window starting from idx=0\n",
    "            sample = get_window(0, window_size)\n",
    "        elif end_idx > last_data_element_idx:\n",
    "            # return window, ending on the last element in the dataset\n",
    "            sample = get_window(last_data_element_idx - window_size, last_data_element_idx)\n",
    "        else:\n",
    "            sample = get_window(begin_idx, end_idx)\n",
    "\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.70043712, 0.84418664, 0.67651434, 0.72785806, 0.95145796,\n       0.0127032 , 0.4135877 , 0.04881279, 0.09992856, 0.50806631,\n       0.20024754, 0.74415417, 0.192892  , 0.70084475, 0.29322811,\n       0.77447945, 0.00510884, 0.11285765, 0.11095367, 0.24766823,\n       0.0232363 , 0.72732115, 0.34003494, 0.19750316, 0.90917959,\n       0.97834699, 0.53280254, 0.25913185, 0.58381262, 0.32569065,\n       0.88889931, 0.62640453, 0.81887369, 0.54734542, 0.41671201,\n       0.74304719, 0.36959638, 0.07516654, 0.77519298, 0.21940924,\n       0.07934213, 0.48678052, 0.1536739 , 0.82846513, 0.19136857,\n       0.27040895, 0.56103442, 0.90238039, 0.85178834, 0.41808196,\n       0.39347627, 0.01622051, 0.29921337, 0.35377822, 0.89350267,\n       0.78613657, 0.77138693, 0.42005486, 0.77602514, 0.46430814,\n       0.18177017, 0.8840256 , 0.71879227, 0.6718813 , 0.25656363,\n       0.43080182, 0.01645358, 0.23499383, 0.51117131, 0.29200924,\n       0.50189351, 0.49827313, 0.10377152, 0.44644312, 0.96918917,\n       0.73847112, 0.71955061, 0.89304339, 0.96267468, 0.19705023,\n       0.71458996, 0.16192394, 0.86625477, 0.62382025, 0.95945512,\n       0.52414204, 0.03643288, 0.72687158, 0.00390984, 0.050294  ,\n       0.99199232, 0.2122575 , 0.94737066, 0.45154055, 0.99879467,\n       0.64750149, 0.70224071, 0.42958177, 0.16777476, 0.11813309])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "n = 100\n",
    "time_series = np.random.random(n)\n",
    "time_series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.93788262, 0.91099744, 0.39799354, 0.92530327, 0.74549922,\n       0.78982636, 0.63770852, 0.99274137, 0.47610554, 0.10211419,\n       0.87256332, 0.75612704, 0.29919884, 0.18625652, 0.49435351,\n       0.0408955 , 0.47835228, 0.3089902 , 0.92058026, 0.91794568,\n       0.46848893, 0.23431308, 0.08982494, 0.67940357, 0.65592832,\n       0.0039444 , 0.06654134, 0.00112109, 0.66608382, 0.38565116,\n       0.09405827, 0.45856757, 0.64434173, 0.59499774, 0.79060307,\n       0.79996907, 0.67969792, 0.43875185, 0.26235889, 0.23652188,\n       0.83900208, 0.36874334, 0.61918838, 0.46656433, 0.49250063,\n       0.71862211, 0.65415881, 0.9665017 , 0.38957233, 0.97017219,\n       0.36057961, 0.56184234, 0.03133558, 0.30480028, 0.07269465,\n       0.46721993, 0.41345069, 0.42228271, 0.79491031, 0.05651855,\n       0.89718201, 0.31869638, 0.36398678, 0.70548804, 0.23103497,\n       0.54827043, 0.3195602 , 0.7302113 , 0.94257233, 0.77442252,\n       0.86379077, 0.82903615, 0.81379647, 0.63166234, 0.68810426,\n       0.09505542, 0.87637271, 0.83280508, 0.42067349, 0.77582558,\n       0.49097792, 0.52603444, 0.71381734, 0.12317237, 0.45279855,\n       0.14136043, 0.34007602, 0.23354548, 0.50744427, 0.42741471,\n       0.53647236, 0.8690842 , 0.84334885, 0.04136067, 0.07753699,\n       0.36800508, 0.74431332, 0.38844287, 0.14635092, 0.37732909])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_time_series = np.random.random(n)\n",
    "cov_time_series"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      target  covariate\n0   0.700437   0.937883\n1   0.844187   0.910997\n2   0.676514   0.397994\n3   0.727858   0.925303\n4   0.951458   0.745499\n..       ...        ...\n95  0.647501   0.368005\n96  0.702241   0.744313\n97  0.429582   0.388443\n98  0.167775   0.146351\n99  0.118133   0.377329\n\n[100 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>covariate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.700437</td>\n      <td>0.937883</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.844187</td>\n      <td>0.910997</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.676514</td>\n      <td>0.397994</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.727858</td>\n      <td>0.925303</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.951458</td>\n      <td>0.745499</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>0.647501</td>\n      <td>0.368005</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.702241</td>\n      <td>0.744313</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.429582</td>\n      <td>0.388443</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.167775</td>\n      <td>0.146351</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.118133</td>\n      <td>0.377329</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_df = pd.DataFrame({'target': time_series, 'covariate': cov_time_series})\n",
    "time_series_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "encoder_length = 10\n",
    "decoder_length = 2\n",
    "training_dataset = TimeSeriesDataset(\n",
    "    df=time_series_df,\n",
    "    targets=['target'],\n",
    "    encoder_len=encoder_length,\n",
    "    decoder_len=decoder_length,\n",
    "    reals=['covariate']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 12, 2])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataloader = DataLoader(\n",
    "    dataset=training_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=8\n",
    ")\n",
    "tst = next(iter(training_dataloader))\n",
    "tst.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from torch import Tensor, log, exp\n",
    "\n",
    "class DeepAR(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            batch_size: int,\n",
    "            hidden_size: int,\n",
    "            input_size: int,\n",
    "            likelihood: str = 'normal',\n",
    "            device: str = 'cpu'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This class instantiates DeepAR.\n",
    "\n",
    "        :param batch_size: size of the batch\n",
    "        :param hidden_size: number of features in hidden state of rnn cell\n",
    "        :param inout_size: number of expected features in the input tensor\n",
    "        :param likelihood: desired likelihood\n",
    "        :param device: device to calculate on\n",
    "        \"\"\"\n",
    "        super(DeepAR, self).__init__()\n",
    "        # here we initialize hidden states\n",
    "        self._h_0 = torch.zeros((batch_size, hidden_size), device=device)\n",
    "        self._c_0 = torch.zeros((batch_size, hidden_size), device=device)\n",
    "        self._likelihood = likelihood\n",
    "        self._device = device\n",
    "\n",
    "        # here we create base architecture of LSTM cell\n",
    "        self._lstm_cell = nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)\n",
    "\n",
    "    @property\n",
    "    def h_0(self):\n",
    "        return self._h_0\n",
    "\n",
    "    @property\n",
    "    def c_0(self):\n",
    "        return self._c_0\n",
    "\n",
    "    @property\n",
    "    def likelihood(self):\n",
    "        return self._likelihood\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return self._device\n",
    "\n",
    "    @property\n",
    "    def lstm_cell(self):\n",
    "        return self._lstm_cell\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            input_tensor: Tensor # [batch_size, seq_len, input_size]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Forward method of our model\n",
    "        :param input_tensor: input tensor [batch_size, seq_len, input_size]\n",
    "        :return: output_tensor: output tensor contains parameters or desired distribution [batch_size, seq_len, num_pars]\n",
    "        \"\"\"\n",
    "        batch_size, hidden_size = self.h_0.shape[0], self.h_0.shape[1]\n",
    "        input_size, seq_len = input_tensor.shape[2], input_tensor.shape[1]\n",
    "        num_pars = 2\n",
    "        if self.likelihood == 'normal':\n",
    "            output_tensor = torch.zeros((batch_size, seq_len, num_pars), device=self.device)\n",
    "        else:\n",
    "            raise NotImplementedError('this likelihood not yet implemented, gl&hf')\n",
    "        # here we iterate through all cells (seq_len)\n",
    "        num_cells = input_tensor.shape[1]\n",
    "\n",
    "        if self.likelihood == 'normal':\n",
    "            for cell_index in range(num_cells):\n",
    "                self._h_0, self._c_0 = self.lstm_cell(input_tensor[:, cell_index, :], (self.h_0, self.c_0))\n",
    "                mean = nn.Linear(in_features=hidden_size, out_features=1)(self.h_0)\n",
    "                variance = log(1 + exp(nn.Linear(in_features=hidden_size, out_features=1)(self.h_0)))\n",
    "                output_tensor[:, cell_index, 0] = torch.flatten(mean)\n",
    "                output_tensor[:, cell_index, 1] = torch.flatten(variance)\n",
    "        else:\n",
    "            raise NotImplementedError('this likelihood not yet implemented, gl&hf')\n",
    "\n",
    "        return output_tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distrib_pars = tensor([[[-0.2184,  0.6173],\n",
      "         [-0.0121,  0.6075],\n",
      "         [-0.2547,  0.6683],\n",
      "         [ 0.0768,  0.8558],\n",
      "         [-0.1699,  0.5325],\n",
      "         [-0.2894,  0.5420],\n",
      "         [-0.1711,  0.8906],\n",
      "         [ 0.2801,  0.7003],\n",
      "         [-0.0904,  0.7947],\n",
      "         [ 0.1464,  0.5530],\n",
      "         [-0.0432,  0.6617],\n",
      "         [ 0.1724,  0.6653]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0736,  0.9317],\n",
      "         [-0.2946,  0.7896],\n",
      "         [-0.1464,  0.6856],\n",
      "         [ 0.1480,  0.5457],\n",
      "         [ 0.2013,  0.7815],\n",
      "         [-0.1202,  0.7254],\n",
      "         [ 0.3004,  0.6818],\n",
      "         [-0.0694,  0.8290],\n",
      "         [-0.1612,  0.7585],\n",
      "         [ 0.3977,  0.7929],\n",
      "         [ 0.2283,  0.7246],\n",
      "         [ 0.3267,  0.6063]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.4221,  0.5970],\n",
      "         [ 0.1728,  0.7327],\n",
      "         [-0.0988,  0.6339],\n",
      "         [ 0.1168,  0.8869],\n",
      "         [ 0.0722,  0.7321],\n",
      "         [ 0.2399,  0.5288],\n",
      "         [-0.2566,  0.6906],\n",
      "         [ 0.2001,  0.7654],\n",
      "         [ 0.1427,  0.8600],\n",
      "         [-0.2251,  0.5756],\n",
      "         [-0.0771,  0.7278],\n",
      "         [ 0.0744,  0.9062]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0236,  0.8351],\n",
      "         [ 0.0975,  0.7488],\n",
      "         [ 0.3747,  0.7972],\n",
      "         [-0.1182,  0.6401],\n",
      "         [-0.2149,  0.6382],\n",
      "         [ 0.0223,  0.5736],\n",
      "         [-0.0529,  0.6414],\n",
      "         [-0.2537,  0.7639],\n",
      "         [ 0.1227,  0.6952],\n",
      "         [ 0.1088,  0.8733],\n",
      "         [-0.2454,  0.5225],\n",
      "         [ 0.0031,  0.6282]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1022,  0.5894],\n",
      "         [ 0.2594,  0.7224],\n",
      "         [-0.0715,  0.7365],\n",
      "         [ 0.4158,  0.8375],\n",
      "         [-0.0801,  0.7809],\n",
      "         [ 0.0565,  0.6787],\n",
      "         [-0.0932,  0.5908],\n",
      "         [ 0.1224,  0.7770],\n",
      "         [ 0.2648,  0.6127],\n",
      "         [-0.1254,  0.7310],\n",
      "         [ 0.4038,  0.7566],\n",
      "         [ 0.2795,  0.5859]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0788,  0.5947],\n",
      "         [ 0.0508,  0.6831],\n",
      "         [-0.3138,  0.6725],\n",
      "         [-0.1903,  0.7346],\n",
      "         [-0.3851,  0.8979],\n",
      "         [-0.2610,  0.5889],\n",
      "         [ 0.3843,  0.7794],\n",
      "         [ 0.0841,  0.7160],\n",
      "         [ 0.0922,  0.5968],\n",
      "         [ 0.0934,  0.7154],\n",
      "         [ 0.2083,  0.5627],\n",
      "         [ 0.0377,  0.9040]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-1.3836e-01,  7.3674e-01],\n",
      "         [-7.8623e-04,  7.1541e-01],\n",
      "         [-1.3334e-01,  5.4150e-01],\n",
      "         [-1.5944e-01,  7.1767e-01],\n",
      "         [-1.7029e-01,  6.5071e-01],\n",
      "         [ 3.2092e-02,  8.3213e-01],\n",
      "         [ 6.8367e-02,  7.1828e-01],\n",
      "         [ 3.3406e-02,  6.2743e-01],\n",
      "         [ 9.1016e-02,  5.7899e-01],\n",
      "         [-2.9664e-03,  7.1589e-01],\n",
      "         [-1.9355e-01,  7.9266e-01],\n",
      "         [ 1.8159e-01,  5.2421e-01]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-2.7535e-01,  6.9520e-01],\n",
      "         [ 2.1687e-01,  5.9544e-01],\n",
      "         [-1.7727e-01,  6.6715e-01],\n",
      "         [ 2.7248e-04,  7.7777e-01],\n",
      "         [-4.5267e-01,  5.6196e-01],\n",
      "         [ 2.2996e-01,  7.4778e-01],\n",
      "         [-8.5521e-02,  7.0193e-01],\n",
      "         [-1.7225e-01,  7.9557e-01],\n",
      "         [-9.8648e-02,  6.8099e-01],\n",
      "         [-1.6704e-01,  7.9215e-01],\n",
      "         [-8.7452e-02,  7.3230e-01],\n",
      "         [-1.4310e-01,  7.0617e-01]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.4153,  0.6211],\n",
      "         [-0.3084,  0.7301],\n",
      "         [ 0.1871,  0.6697],\n",
      "         [ 0.1074,  0.5926],\n",
      "         [ 0.0014,  0.8061],\n",
      "         [-0.1816,  0.7530],\n",
      "         [-0.1834,  0.6159],\n",
      "         [ 0.0104,  0.6177],\n",
      "         [ 0.3142,  0.6839],\n",
      "         [ 0.2534,  0.7624],\n",
      "         [ 0.3773,  0.5452],\n",
      "         [ 0.0156,  0.6916]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0464,  0.7268],\n",
      "         [ 0.0131,  0.8330],\n",
      "         [-0.1660,  0.6091],\n",
      "         [-0.1516,  0.8325],\n",
      "         [ 0.0587,  0.7652],\n",
      "         [ 0.1534,  0.6627],\n",
      "         [ 0.2456,  0.6497],\n",
      "         [ 0.1389,  0.7204],\n",
      "         [-0.3975,  0.6715],\n",
      "         [-0.2683,  0.8131],\n",
      "         [ 0.0068,  0.6076],\n",
      "         [-0.0567,  0.6650]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2524,  0.5969],\n",
      "         [-0.4009,  0.7737],\n",
      "         [-0.1735,  0.8037],\n",
      "         [ 0.2006,  0.6533],\n",
      "         [-0.2112,  0.6807],\n",
      "         [-0.2766,  0.6962],\n",
      "         [ 0.1891,  0.5265],\n",
      "         [-0.1842,  0.5651],\n",
      "         [-0.2805,  0.7234],\n",
      "         [ 0.1784,  0.6742],\n",
      "         [-0.1143,  0.8100],\n",
      "         [-0.0859,  0.5992]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3011,  0.7357],\n",
      "         [ 0.0041,  0.7488],\n",
      "         [ 0.1624,  0.7370],\n",
      "         [-0.2524,  0.6367],\n",
      "         [ 0.2706,  0.6664],\n",
      "         [ 0.2050,  0.7560],\n",
      "         [ 0.0266,  0.7901],\n",
      "         [ 0.1727,  0.7512],\n",
      "         [-0.2874,  0.6887],\n",
      "         [-0.1949,  0.6633],\n",
      "         [ 0.1010,  0.6637],\n",
      "         [ 0.2630,  0.5522]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1822,  0.5683],\n",
      "         [ 0.1805,  0.5985],\n",
      "         [ 0.2138,  0.6101],\n",
      "         [ 0.2349,  0.6791],\n",
      "         [ 0.3582,  0.5693],\n",
      "         [-0.4050,  0.7731],\n",
      "         [ 0.1445,  0.8527],\n",
      "         [-0.2805,  0.7251],\n",
      "         [-0.1617,  0.7312],\n",
      "         [-0.2985,  0.7296],\n",
      "         [ 0.2494,  0.6143],\n",
      "         [ 0.0261,  0.7396]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1548,  0.6605],\n",
      "         [ 0.3628,  0.6686],\n",
      "         [ 0.1453,  0.7863],\n",
      "         [-0.2297,  0.8841],\n",
      "         [ 0.0606,  0.5118],\n",
      "         [ 0.2535,  0.7158],\n",
      "         [-0.2286,  0.7395],\n",
      "         [-0.2933,  0.5973],\n",
      "         [ 0.0245,  0.6292],\n",
      "         [-0.1220,  0.7520],\n",
      "         [ 0.2791,  0.5743],\n",
      "         [-0.0675,  0.6118]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 8.8382e-02,  6.0243e-01],\n",
      "         [-9.2369e-04,  6.0331e-01],\n",
      "         [-4.9850e-02,  6.9882e-01],\n",
      "         [-6.9918e-02,  6.6126e-01],\n",
      "         [ 6.6713e-02,  6.7529e-01],\n",
      "         [-2.2282e-01,  7.4243e-01],\n",
      "         [-2.5799e-01,  9.3410e-01],\n",
      "         [ 2.0350e-01,  6.2716e-01],\n",
      "         [ 4.4801e-03,  6.5707e-01],\n",
      "         [ 7.6439e-03,  6.8125e-01],\n",
      "         [-3.8498e-02,  8.1110e-01],\n",
      "         [ 3.0716e-01,  6.5191e-01]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1175,  0.7107],\n",
      "         [ 0.0507,  0.6589],\n",
      "         [ 0.1554,  0.8638],\n",
      "         [ 0.0163,  0.7773],\n",
      "         [ 0.0535,  0.6531],\n",
      "         [-0.1364,  0.8051],\n",
      "         [ 0.2643,  0.8800],\n",
      "         [-0.1631,  0.6092],\n",
      "         [ 0.2270,  0.6207],\n",
      "         [-0.2188,  0.7312],\n",
      "         [ 0.0656,  0.7659],\n",
      "         [-0.2150,  0.6966]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1569,  0.8991],\n",
      "         [ 0.1111,  0.7043],\n",
      "         [-0.1399,  0.7854],\n",
      "         [-0.2597,  0.6979],\n",
      "         [ 0.0066,  0.7724],\n",
      "         [-0.2592,  0.8615],\n",
      "         [ 0.2438,  0.5927],\n",
      "         [ 0.1725,  0.9327],\n",
      "         [-0.1705,  0.6736],\n",
      "         [ 0.1617,  0.5642],\n",
      "         [-0.2197,  0.6889],\n",
      "         [-0.3390,  0.7261]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0738,  0.7710],\n",
      "         [ 0.4846,  0.7855],\n",
      "         [ 0.1095,  0.6604],\n",
      "         [-0.1268,  0.7261],\n",
      "         [-0.1460,  0.5834],\n",
      "         [ 0.1180,  0.8006],\n",
      "         [-0.1155,  0.6290],\n",
      "         [-0.1224,  0.7659],\n",
      "         [ 0.2443,  0.6833],\n",
      "         [ 0.1546,  0.8621],\n",
      "         [-0.1918,  0.7602],\n",
      "         [ 0.0996,  0.5705]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.3545,  0.5195],\n",
      "         [-0.0764,  0.5812],\n",
      "         [ 0.1601,  0.5284],\n",
      "         [-0.1007,  0.7526],\n",
      "         [-0.0728,  0.5460],\n",
      "         [-0.1151,  0.7532],\n",
      "         [-0.0576,  0.7196],\n",
      "         [ 0.0055,  0.7548],\n",
      "         [ 0.3112,  0.6549],\n",
      "         [ 0.1936,  0.6333],\n",
      "         [-0.0547,  0.7557],\n",
      "         [-0.1845,  0.7621]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1987,  0.6194],\n",
      "         [ 0.0401,  0.5859],\n",
      "         [ 0.0139,  0.6885],\n",
      "         [ 0.0751,  0.7290],\n",
      "         [ 0.2202,  0.5629],\n",
      "         [-0.1199,  0.5997],\n",
      "         [-0.3388,  0.6780],\n",
      "         [-0.3341,  0.7593],\n",
      "         [-0.0982,  0.6115],\n",
      "         [ 0.1730,  0.5359],\n",
      "         [ 0.2005,  0.6340],\n",
      "         [ 0.0797,  0.7875]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1983,  0.7782],\n",
      "         [ 0.1553,  0.6901],\n",
      "         [-0.1845,  0.7246],\n",
      "         [ 0.2862,  0.6572],\n",
      "         [-0.1784,  0.5993],\n",
      "         [ 0.3313,  0.7609],\n",
      "         [ 0.4619,  0.8457],\n",
      "         [-0.0263,  0.7769],\n",
      "         [-0.0013,  0.6657],\n",
      "         [-0.2157,  0.7537],\n",
      "         [ 0.1589,  0.7328],\n",
      "         [ 0.1485,  0.6141]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1182,  0.6619],\n",
      "         [-0.2836,  0.8358],\n",
      "         [ 0.0860,  0.5232],\n",
      "         [-0.3476,  0.7899],\n",
      "         [ 0.2388,  0.8140],\n",
      "         [ 0.0283,  0.5647],\n",
      "         [-0.1003,  0.5687],\n",
      "         [-0.0567,  0.5253],\n",
      "         [-0.1653,  0.6510],\n",
      "         [ 0.1333,  0.7549],\n",
      "         [-0.0726,  0.5948],\n",
      "         [-0.0852,  0.6187]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1497,  0.5551],\n",
      "         [-0.2010,  0.6552],\n",
      "         [-0.0713,  0.8156],\n",
      "         [-0.1990,  0.8341],\n",
      "         [ 0.0752,  0.6285],\n",
      "         [ 0.1204,  0.6572],\n",
      "         [ 0.1487,  0.7940],\n",
      "         [ 0.1282,  0.7995],\n",
      "         [-0.2377,  0.7250],\n",
      "         [-0.2793,  0.9455],\n",
      "         [-0.1311,  0.6494],\n",
      "         [-0.2785,  0.6022]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2443,  0.5793],\n",
      "         [-0.0885,  0.6436],\n",
      "         [-0.1887,  0.7197],\n",
      "         [ 0.1422,  0.6595],\n",
      "         [ 0.0787,  0.8198],\n",
      "         [ 0.2522,  0.6191],\n",
      "         [-0.2143,  0.6107],\n",
      "         [-0.2958,  0.5733],\n",
      "         [ 0.1706,  0.6285],\n",
      "         [ 0.1827,  0.6317],\n",
      "         [ 0.1297,  0.7177],\n",
      "         [ 0.0851,  0.7460]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1173,  0.6430],\n",
      "         [ 0.0676,  0.7221],\n",
      "         [-0.2624,  0.5651],\n",
      "         [-0.1334,  0.5710],\n",
      "         [ 0.3027,  0.9035],\n",
      "         [ 0.2086,  0.8421],\n",
      "         [ 0.1426,  0.9439],\n",
      "         [-0.2830,  0.8094],\n",
      "         [ 0.1481,  0.5045],\n",
      "         [ 0.0321,  0.7484],\n",
      "         [ 0.1453,  0.7847],\n",
      "         [-0.1438,  0.5869]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1775,  0.8122],\n",
      "         [ 0.1467,  0.8407],\n",
      "         [-0.2580,  0.6393],\n",
      "         [-0.1497,  0.7307],\n",
      "         [ 0.1246,  0.6832],\n",
      "         [-0.2808,  0.6003],\n",
      "         [-0.1126,  0.5980],\n",
      "         [ 0.0780,  0.5627],\n",
      "         [ 0.0896,  0.6370],\n",
      "         [ 0.2327,  0.5632],\n",
      "         [ 0.1793,  0.6462],\n",
      "         [ 0.0860,  0.6854]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0042,  0.6535],\n",
      "         [-0.2060,  0.6765],\n",
      "         [-0.1846,  0.7663],\n",
      "         [-0.3250,  0.6874],\n",
      "         [-0.0558,  0.6751],\n",
      "         [-0.0433,  0.6850],\n",
      "         [ 0.1756,  0.6537],\n",
      "         [ 0.1004,  0.6336],\n",
      "         [ 0.0821,  0.7316],\n",
      "         [-0.1221,  0.8103],\n",
      "         [ 0.1203,  0.7550],\n",
      "         [ 0.1463,  0.7935]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3047,  0.7903],\n",
      "         [ 0.0784,  0.6264],\n",
      "         [-0.1137,  0.5447],\n",
      "         [-0.0601,  0.5978],\n",
      "         [-0.1028,  0.8208],\n",
      "         [-0.0976,  0.7416],\n",
      "         [ 0.0735,  0.6979],\n",
      "         [-0.3439,  0.6433],\n",
      "         [-0.2640,  0.6613],\n",
      "         [ 0.3349,  0.7070],\n",
      "         [ 0.0217,  0.6549],\n",
      "         [-0.1275,  0.6247]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0658,  0.7978],\n",
      "         [ 0.0949,  0.7761],\n",
      "         [ 0.2154,  0.6458],\n",
      "         [ 0.1549,  0.6431],\n",
      "         [ 0.0899,  0.8491],\n",
      "         [ 0.2610,  0.7818],\n",
      "         [ 0.2619,  0.7240],\n",
      "         [-0.1974,  0.6687],\n",
      "         [-0.0334,  0.7974],\n",
      "         [ 0.0855,  0.7075],\n",
      "         [ 0.2511,  0.8075],\n",
      "         [-0.0051,  0.7379]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2283,  0.6913],\n",
      "         [ 0.0156,  0.7096],\n",
      "         [-0.1336,  0.6869],\n",
      "         [ 0.1343,  0.8184],\n",
      "         [-0.0854,  0.7524],\n",
      "         [-0.0142,  0.6982],\n",
      "         [ 0.3401,  0.6596],\n",
      "         [ 0.1205,  0.6054],\n",
      "         [ 0.1418,  0.8033],\n",
      "         [-0.1150,  0.5875],\n",
      "         [ 0.0078,  0.6723],\n",
      "         [-0.1094,  0.8204]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.4125,  0.6572],\n",
      "         [-0.2764,  0.6396],\n",
      "         [-0.2057,  0.7876],\n",
      "         [ 0.1689,  0.8221],\n",
      "         [-0.3581,  0.7994],\n",
      "         [-0.1638,  0.7793],\n",
      "         [-0.1528,  0.6376],\n",
      "         [-0.2056,  0.5653],\n",
      "         [-0.1055,  0.7063],\n",
      "         [-0.2268,  0.6237],\n",
      "         [ 0.1105,  0.7771],\n",
      "         [-0.0732,  0.7872]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2684,  0.6868],\n",
      "         [-0.1048,  0.7411],\n",
      "         [-0.2210,  0.5867],\n",
      "         [-0.0344,  0.5752],\n",
      "         [-0.0839,  0.7734],\n",
      "         [ 0.1506,  0.6592],\n",
      "         [ 0.0496,  0.8091],\n",
      "         [-0.3036,  0.5158],\n",
      "         [-0.1684,  0.8714],\n",
      "         [ 0.1766,  0.7459],\n",
      "         [ 0.1098,  0.8967],\n",
      "         [-0.0173,  0.8789]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1222,  0.7850],\n",
      "         [ 0.1616,  0.8898],\n",
      "         [-0.0694,  0.8451],\n",
      "         [ 0.0691,  0.7122],\n",
      "         [-0.0751,  0.8039],\n",
      "         [-0.0249,  0.6966],\n",
      "         [-0.1146,  0.6582],\n",
      "         [-0.0084,  0.7411],\n",
      "         [ 0.1588,  0.8073],\n",
      "         [ 0.0549,  0.6917],\n",
      "         [-0.0364,  0.5599],\n",
      "         [ 0.2108,  0.7875]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.3609,  0.5776],\n",
      "         [ 0.1730,  0.6934],\n",
      "         [ 0.0195,  0.6335],\n",
      "         [ 0.3942,  0.9164],\n",
      "         [ 0.0217,  0.5922],\n",
      "         [-0.0192,  0.6005],\n",
      "         [-0.1930,  0.5496],\n",
      "         [ 0.0423,  0.6127],\n",
      "         [ 0.0349,  0.7737],\n",
      "         [ 0.3562,  0.6716],\n",
      "         [ 0.1441,  0.6077],\n",
      "         [ 0.2112,  0.9312]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0508,  0.7375],\n",
      "         [ 0.0815,  0.8374],\n",
      "         [ 0.0018,  0.5607],\n",
      "         [-0.1783,  0.6102],\n",
      "         [ 0.0066,  0.6187],\n",
      "         [ 0.1018,  0.5994],\n",
      "         [ 0.0868,  0.7807],\n",
      "         [ 0.0504,  0.6754],\n",
      "         [ 0.1974,  0.8019],\n",
      "         [-0.1089,  0.6905],\n",
      "         [-0.2358,  0.8866],\n",
      "         [-0.1952,  0.7868]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2296,  0.6211],\n",
      "         [-0.2922,  0.7475],\n",
      "         [-0.3198,  0.6465],\n",
      "         [-0.1891,  0.5614],\n",
      "         [ 0.1534,  0.5782],\n",
      "         [ 0.0359,  0.7312],\n",
      "         [ 0.0705,  0.5199],\n",
      "         [-0.0267,  0.6690],\n",
      "         [ 0.1120,  0.7124],\n",
      "         [-0.1490,  0.5884],\n",
      "         [ 0.0127,  0.5571],\n",
      "         [-0.1471,  0.6789]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1518,  0.8032],\n",
      "         [-0.0489,  0.5999],\n",
      "         [ 0.3894,  0.7026],\n",
      "         [-0.0661,  0.7556],\n",
      "         [ 0.0919,  0.5755],\n",
      "         [ 0.1479,  0.6255],\n",
      "         [-0.3191,  0.5988],\n",
      "         [-0.1488,  0.8297],\n",
      "         [-0.2353,  0.6281],\n",
      "         [-0.0627,  0.8934],\n",
      "         [ 0.0515,  0.6549],\n",
      "         [-0.2726,  0.6888]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0257,  0.7729],\n",
      "         [ 0.1125,  0.6171],\n",
      "         [-0.0589,  0.6289],\n",
      "         [-0.1281,  0.6564],\n",
      "         [-0.1036,  0.8749],\n",
      "         [ 0.1081,  0.4850],\n",
      "         [-0.0798,  0.5291],\n",
      "         [-0.1701,  0.6889],\n",
      "         [-0.2382,  0.7645],\n",
      "         [-0.1030,  0.8165],\n",
      "         [-0.0667,  0.7675],\n",
      "         [-0.0589,  0.6166]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-1.2060e-02,  5.7612e-01],\n",
      "         [ 1.3520e-01,  5.5061e-01],\n",
      "         [-1.5321e-01,  8.4532e-01],\n",
      "         [ 5.0246e-02,  8.1654e-01],\n",
      "         [-8.5364e-02,  6.9399e-01],\n",
      "         [-1.0414e-02,  6.3066e-01],\n",
      "         [ 3.3714e-01,  7.4869e-01],\n",
      "         [ 3.4915e-01,  6.3515e-01],\n",
      "         [-7.1171e-04,  7.5755e-01],\n",
      "         [-2.0443e-01,  6.4719e-01],\n",
      "         [-2.6317e-01,  6.0869e-01],\n",
      "         [-1.2678e-02,  6.8500e-01]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.3794,  0.8168],\n",
      "         [-0.0553,  0.8834],\n",
      "         [-0.2153,  0.7160],\n",
      "         [ 0.3656,  0.8336],\n",
      "         [-0.1504,  0.6940],\n",
      "         [ 0.1671,  0.5871],\n",
      "         [-0.3390,  0.6270],\n",
      "         [-0.1701,  0.8455],\n",
      "         [ 0.0380,  0.7004],\n",
      "         [-0.2550,  0.7107],\n",
      "         [-0.2282,  0.6851],\n",
      "         [-0.1832,  0.6336]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1543,  0.7394],\n",
      "         [ 0.1834,  0.6011],\n",
      "         [-0.0735,  0.6368],\n",
      "         [ 0.2572,  0.8152],\n",
      "         [ 0.0769,  0.8357],\n",
      "         [ 0.2599,  0.9000],\n",
      "         [ 0.2176,  0.6967],\n",
      "         [ 0.1848,  0.6640],\n",
      "         [-0.0610,  0.6492],\n",
      "         [ 0.1122,  0.5889],\n",
      "         [-0.0828,  0.6790],\n",
      "         [ 0.2934,  0.8049]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0886,  0.6747],\n",
      "         [ 0.0523,  0.6984],\n",
      "         [ 0.1530,  0.7927],\n",
      "         [ 0.1768,  0.6692],\n",
      "         [ 0.1545,  0.6128],\n",
      "         [ 0.3611,  0.8075],\n",
      "         [ 0.1534,  0.7031],\n",
      "         [-0.1943,  0.5784],\n",
      "         [-0.2385,  0.8197],\n",
      "         [-0.2435,  0.8520],\n",
      "         [-0.3263,  0.7925],\n",
      "         [-0.1257,  0.8140]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0577,  0.8320],\n",
      "         [-0.0563,  0.6366],\n",
      "         [ 0.2689,  0.6797],\n",
      "         [ 0.1971,  0.5484],\n",
      "         [-0.0398,  0.6266],\n",
      "         [ 0.2011,  0.5770],\n",
      "         [-0.0988,  0.6923],\n",
      "         [ 0.4191,  0.7161],\n",
      "         [-0.2493,  0.6871],\n",
      "         [-0.3402,  0.6720],\n",
      "         [ 0.2432,  0.8221],\n",
      "         [ 0.2415,  0.6729]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0586,  0.6864],\n",
      "         [-0.0150,  0.8270],\n",
      "         [-0.0305,  0.7102],\n",
      "         [ 0.0658,  0.6941],\n",
      "         [-0.0066,  0.6898],\n",
      "         [ 0.1377,  0.8130],\n",
      "         [-0.0274,  0.7346],\n",
      "         [-0.4210,  0.6822],\n",
      "         [ 0.1407,  0.6875],\n",
      "         [-0.1681,  0.7757],\n",
      "         [-0.2699,  0.5854],\n",
      "         [-0.0130,  0.5205]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2449,  0.7081],\n",
      "         [ 0.0827,  0.6184],\n",
      "         [ 0.0891,  0.6887],\n",
      "         [ 0.1078,  0.7978],\n",
      "         [-0.1595,  0.7791],\n",
      "         [-0.1809,  0.8444],\n",
      "         [-0.3262,  0.7593],\n",
      "         [-0.2851,  0.7478],\n",
      "         [ 0.0717,  0.7723],\n",
      "         [-0.3143,  0.7735],\n",
      "         [-0.3480,  0.7209],\n",
      "         [-0.0062,  0.6886]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1780,  0.8228],\n",
      "         [ 0.0994,  0.7263],\n",
      "         [ 0.1991,  0.9076],\n",
      "         [ 0.0098,  0.7496],\n",
      "         [ 0.0332,  0.8280],\n",
      "         [ 0.2992,  0.6932],\n",
      "         [-0.2878,  0.5720],\n",
      "         [-0.0420,  0.6779],\n",
      "         [-0.3578,  0.7975],\n",
      "         [-0.0743,  0.5454],\n",
      "         [ 0.1587,  0.6839],\n",
      "         [-0.2030,  0.6803]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0821,  0.9015],\n",
      "         [-0.2528,  0.8901],\n",
      "         [ 0.4133,  0.6657],\n",
      "         [-0.0560,  0.7547],\n",
      "         [-0.0430,  0.7050],\n",
      "         [-0.0450,  0.5725],\n",
      "         [-0.0178,  0.8015],\n",
      "         [ 0.1048,  0.6577],\n",
      "         [ 0.0900,  0.5909],\n",
      "         [ 0.0315,  0.7139],\n",
      "         [ 0.3666,  0.6426],\n",
      "         [-0.0435,  0.7202]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1065,  0.6099],\n",
      "         [ 0.1893,  0.6478],\n",
      "         [-0.2255,  0.9467],\n",
      "         [-0.1530,  0.6760],\n",
      "         [-0.1629,  0.5940],\n",
      "         [-0.1297,  0.6659],\n",
      "         [-0.1117,  0.5144],\n",
      "         [ 0.2111,  0.8412],\n",
      "         [-0.0180,  0.7493],\n",
      "         [-0.1292,  0.6294],\n",
      "         [-0.0925,  0.6232],\n",
      "         [ 0.2048,  0.8112]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0351,  0.6325],\n",
      "         [-0.1497,  0.6624],\n",
      "         [-0.2335,  0.5269],\n",
      "         [-0.1155,  0.6538],\n",
      "         [ 0.1003,  0.6584],\n",
      "         [ 0.1054,  0.7444],\n",
      "         [ 0.3126,  0.8099],\n",
      "         [ 0.1236,  0.7888],\n",
      "         [ 0.1097,  0.6972],\n",
      "         [-0.2656,  0.6267],\n",
      "         [ 0.2439,  0.8290],\n",
      "         [ 0.0023,  0.4874]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2584,  0.7691],\n",
      "         [-0.0042,  0.8530],\n",
      "         [-0.2293,  0.8458],\n",
      "         [ 0.1713,  0.7016],\n",
      "         [-0.4190,  0.7536],\n",
      "         [ 0.1706,  0.5772],\n",
      "         [ 0.0641,  0.5817],\n",
      "         [-0.1201,  0.7023],\n",
      "         [-0.0885,  0.7681],\n",
      "         [ 0.0956,  0.8078],\n",
      "         [ 0.0806,  0.7587],\n",
      "         [ 0.1394,  0.7701]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2075,  0.5570],\n",
      "         [ 0.1461,  0.6145],\n",
      "         [ 0.3940,  0.5181],\n",
      "         [ 0.0434,  0.6876],\n",
      "         [ 0.0679,  0.6134],\n",
      "         [-0.1541,  0.9165],\n",
      "         [-0.0326,  0.6635],\n",
      "         [-0.1918,  0.5528],\n",
      "         [ 0.0363,  0.7073],\n",
      "         [-0.3355,  0.8534],\n",
      "         [-0.2624,  0.6477],\n",
      "         [-0.3410,  0.6863]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0401,  0.7170],\n",
      "         [-0.2033,  0.5491],\n",
      "         [-0.3553,  0.8012],\n",
      "         [-0.1120,  0.5300],\n",
      "         [-0.1956,  0.8501],\n",
      "         [ 0.2608,  0.6635],\n",
      "         [ 0.0637,  0.6774],\n",
      "         [-0.1361,  0.8754],\n",
      "         [-0.1837,  0.6433],\n",
      "         [ 0.0365,  0.5604],\n",
      "         [ 0.1712,  0.5832],\n",
      "         [-0.2418,  0.7967]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1600,  0.5478],\n",
      "         [ 0.2949,  0.6121],\n",
      "         [-0.3150,  0.7001],\n",
      "         [-0.0878,  0.7330],\n",
      "         [-0.2662,  0.5511],\n",
      "         [ 0.0435,  0.6952],\n",
      "         [-0.0309,  0.5917],\n",
      "         [ 0.2599,  0.8355],\n",
      "         [-0.0422,  0.8135],\n",
      "         [-0.1753,  0.5530],\n",
      "         [ 0.0981,  0.8775],\n",
      "         [-0.1483,  0.7831]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1282,  0.5220],\n",
      "         [-0.0273,  0.8758],\n",
      "         [ 0.0072,  0.7435],\n",
      "         [-0.0121,  0.8411],\n",
      "         [-0.0119,  0.7984],\n",
      "         [ 0.0476,  0.6662],\n",
      "         [ 0.2165,  0.5899],\n",
      "         [ 0.1587,  0.8560],\n",
      "         [-0.1948,  0.5851],\n",
      "         [ 0.1390,  0.5267],\n",
      "         [ 0.0083,  0.7752],\n",
      "         [ 0.0796,  0.6810]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2493,  0.6552],\n",
      "         [ 0.2729,  0.7286],\n",
      "         [ 0.0443,  0.6910],\n",
      "         [ 0.1581,  0.6609],\n",
      "         [-0.2580,  0.5974],\n",
      "         [ 0.0046,  0.6931],\n",
      "         [-0.1559,  0.6332],\n",
      "         [ 0.4252,  0.5278],\n",
      "         [-0.1525,  0.8366],\n",
      "         [ 0.1864,  0.6716],\n",
      "         [-0.3331,  0.7436],\n",
      "         [ 0.1025,  0.7968]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1407,  0.6845],\n",
      "         [ 0.1167,  0.6043],\n",
      "         [ 0.1321,  0.7393],\n",
      "         [ 0.0325,  0.5899],\n",
      "         [-0.0472,  0.7654],\n",
      "         [ 0.0683,  0.6817],\n",
      "         [-0.0093,  0.7946],\n",
      "         [ 0.3008,  0.7189],\n",
      "         [-0.0476,  0.7661],\n",
      "         [-0.1862,  0.8643],\n",
      "         [-0.0599,  0.6026],\n",
      "         [-0.3563,  0.6820]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1138,  0.6240],\n",
      "         [-0.1906,  0.8402],\n",
      "         [ 0.3615,  0.8185],\n",
      "         [ 0.1452,  0.5694],\n",
      "         [-0.1889,  0.7463],\n",
      "         [-0.2820,  0.6601],\n",
      "         [-0.3451,  0.7611],\n",
      "         [-0.1394,  0.6455],\n",
      "         [-0.0210,  0.6771],\n",
      "         [ 0.0034,  0.6931],\n",
      "         [-0.0550,  0.8139],\n",
      "         [ 0.3642,  0.8207]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2555,  0.6591],\n",
      "         [ 0.0923,  0.7105],\n",
      "         [ 0.0742,  0.6695],\n",
      "         [ 0.0341,  0.6392],\n",
      "         [-0.2063,  0.7932],\n",
      "         [-0.1875,  0.7826],\n",
      "         [ 0.2176,  0.8204],\n",
      "         [-0.0166,  0.7786],\n",
      "         [-0.0423,  0.6439],\n",
      "         [ 0.1911,  0.7697],\n",
      "         [ 0.2366,  0.7687],\n",
      "         [-0.1267,  0.7483]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2458,  0.6493],\n",
      "         [-0.2260,  0.7899],\n",
      "         [-0.1159,  0.6402],\n",
      "         [ 0.1567,  0.7685],\n",
      "         [ 0.0702,  0.5838],\n",
      "         [ 0.0816,  0.5556],\n",
      "         [-0.0586,  0.5976],\n",
      "         [ 0.3616,  0.5906],\n",
      "         [-0.1368,  0.7581],\n",
      "         [ 0.2178,  0.7408],\n",
      "         [ 0.1526,  0.6022],\n",
      "         [ 0.2527,  0.5459]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0961,  0.7180],\n",
      "         [-0.0758,  0.7693],\n",
      "         [ 0.1844,  0.6014],\n",
      "         [-0.0219,  0.8073],\n",
      "         [ 0.0361,  0.6493],\n",
      "         [-0.2106,  0.8620],\n",
      "         [-0.0485,  0.5810],\n",
      "         [-0.1535,  0.7619],\n",
      "         [ 0.3890,  0.7635],\n",
      "         [-0.1286,  0.8699],\n",
      "         [ 0.1638,  0.6678],\n",
      "         [ 0.1463,  0.8300]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1035,  0.7573],\n",
      "         [-0.0801,  0.6967],\n",
      "         [ 0.1431,  0.7425],\n",
      "         [ 0.2691,  0.7586],\n",
      "         [-0.1194,  0.6824],\n",
      "         [ 0.0038,  0.6139],\n",
      "         [-0.1892,  0.7052],\n",
      "         [ 0.1196,  0.6451],\n",
      "         [-0.1738,  0.7018],\n",
      "         [-0.0822,  0.6651],\n",
      "         [ 0.0641,  0.5985],\n",
      "         [ 0.1284,  0.8029]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1567,  0.7564],\n",
      "         [-0.0941,  0.5852],\n",
      "         [ 0.0687,  0.6433],\n",
      "         [ 0.0038,  0.7340],\n",
      "         [ 0.0335,  0.7303],\n",
      "         [ 0.1194,  0.8347],\n",
      "         [-0.1384,  0.8029],\n",
      "         [ 0.3178,  0.7140],\n",
      "         [-0.4674,  0.8078],\n",
      "         [ 0.0238,  0.7718],\n",
      "         [ 0.1672,  0.6291],\n",
      "         [ 0.1749,  0.6879]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2974,  0.6808],\n",
      "         [-0.0531,  0.7112],\n",
      "         [ 0.1938,  0.6497],\n",
      "         [ 0.1036,  0.7215],\n",
      "         [ 0.0840,  0.7882],\n",
      "         [ 0.1438,  0.6060],\n",
      "         [ 0.4033,  0.5470],\n",
      "         [ 0.0901,  0.6407],\n",
      "         [-0.0217,  0.7801],\n",
      "         [ 0.0179,  0.6413],\n",
      "         [ 0.4951,  0.6496],\n",
      "         [ 0.1333,  0.6864]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2817,  0.5886],\n",
      "         [ 0.0707,  0.6550],\n",
      "         [ 0.1376,  0.7653],\n",
      "         [-0.1884,  0.6438],\n",
      "         [ 0.3368,  0.7300],\n",
      "         [ 0.1291,  0.7388],\n",
      "         [ 0.1441,  0.7041],\n",
      "         [-0.0301,  0.6662],\n",
      "         [ 0.0644,  0.6436],\n",
      "         [-0.0766,  0.6232],\n",
      "         [ 0.1588,  0.6778],\n",
      "         [ 0.0492,  0.5011]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0500,  0.7944],\n",
      "         [ 0.1296,  0.7228],\n",
      "         [ 0.0181,  0.6793],\n",
      "         [ 0.2138,  0.7287],\n",
      "         [-0.1278,  0.6993],\n",
      "         [ 0.0604,  0.6968],\n",
      "         [-0.2265,  0.8469],\n",
      "         [ 0.0038,  0.6289],\n",
      "         [ 0.0208,  0.7905],\n",
      "         [-0.3162,  0.8422],\n",
      "         [ 0.2612,  0.6622],\n",
      "         [-0.1363,  0.7524]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0961,  0.6666],\n",
      "         [ 0.2945,  0.5885],\n",
      "         [ 0.1223,  0.7788],\n",
      "         [ 0.0380,  0.6095],\n",
      "         [-0.1609,  0.7297],\n",
      "         [-0.1263,  0.7396],\n",
      "         [ 0.0338,  0.7465],\n",
      "         [ 0.0724,  0.6050],\n",
      "         [-0.0703,  0.8017],\n",
      "         [ 0.1760,  0.6061],\n",
      "         [-0.0605,  0.5981],\n",
      "         [ 0.2997,  0.6946]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2384,  0.7458],\n",
      "         [-0.2189,  0.7854],\n",
      "         [ 0.2384,  0.7441],\n",
      "         [ 0.0390,  0.6102],\n",
      "         [ 0.0316,  0.6484],\n",
      "         [-0.0626,  0.7127],\n",
      "         [-0.1165,  0.9146],\n",
      "         [-0.0068,  0.6952],\n",
      "         [ 0.0475,  0.5379],\n",
      "         [ 0.0777,  0.5794],\n",
      "         [-0.1352,  0.6355],\n",
      "         [ 0.2914,  0.5704]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0112,  0.8583],\n",
      "         [ 0.2490,  0.6311],\n",
      "         [-0.0572,  0.6651],\n",
      "         [ 0.0601,  0.7132],\n",
      "         [-0.0591,  0.6407],\n",
      "         [-0.1842,  0.6409],\n",
      "         [ 0.1545,  0.7618],\n",
      "         [ 0.1584,  0.6864],\n",
      "         [ 0.2809,  0.8149],\n",
      "         [-0.4416,  0.6748],\n",
      "         [ 0.1743,  0.7398],\n",
      "         [ 0.3323,  0.5812]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0823,  0.7270],\n",
      "         [-0.0367,  0.6363],\n",
      "         [-0.0650,  0.8738],\n",
      "         [-0.2564,  0.7084],\n",
      "         [ 0.1268,  0.5959],\n",
      "         [ 0.3748,  0.8280],\n",
      "         [-0.3694,  0.7945],\n",
      "         [ 0.1084,  0.5945],\n",
      "         [ 0.0366,  0.5791],\n",
      "         [ 0.0712,  0.5857],\n",
      "         [-0.1712,  0.6753],\n",
      "         [ 0.1540,  0.8558]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.4284,  0.7131],\n",
      "         [-0.2414,  0.6134],\n",
      "         [-0.2532,  0.8592],\n",
      "         [-0.1490,  0.7091],\n",
      "         [-0.1170,  0.8094],\n",
      "         [-0.0998,  0.5141],\n",
      "         [ 0.1638,  0.7328],\n",
      "         [ 0.0612,  0.6442],\n",
      "         [-0.1600,  0.5708],\n",
      "         [ 0.2215,  0.8109],\n",
      "         [-0.1968,  0.7491],\n",
      "         [ 0.0623,  0.7779]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0836,  0.7255],\n",
      "         [ 0.1317,  0.6429],\n",
      "         [-0.1293,  0.6479],\n",
      "         [-0.3031,  0.7182],\n",
      "         [ 0.1781,  0.6634],\n",
      "         [ 0.1530,  0.7625],\n",
      "         [-0.3335,  0.6586],\n",
      "         [-0.1715,  0.5411],\n",
      "         [ 0.1334,  0.6775],\n",
      "         [ 0.1443,  0.5323],\n",
      "         [ 0.5270,  0.6679],\n",
      "         [ 0.1380,  0.7966]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2359,  0.5133],\n",
      "         [-0.1524,  0.6692],\n",
      "         [ 0.0260,  0.8049],\n",
      "         [-0.1989,  0.8002],\n",
      "         [ 0.2531,  0.6420],\n",
      "         [-0.2887,  0.7408],\n",
      "         [ 0.3455,  0.5961],\n",
      "         [-0.0936,  0.6998],\n",
      "         [ 0.1406,  0.6222],\n",
      "         [ 0.0736,  0.8535],\n",
      "         [-0.3187,  0.6668],\n",
      "         [-0.0099,  0.6895]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3184,  0.8378],\n",
      "         [ 0.0955,  0.6971],\n",
      "         [-0.1613,  0.7965],\n",
      "         [-0.0649,  0.7661],\n",
      "         [ 0.3611,  0.6556],\n",
      "         [ 0.1031,  0.6399],\n",
      "         [ 0.2544,  0.6095],\n",
      "         [-0.2197,  0.6376],\n",
      "         [ 0.1096,  0.6182],\n",
      "         [ 0.3144,  0.6196],\n",
      "         [-0.2388,  0.5917],\n",
      "         [-0.3142,  0.6513]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.1210,  0.6857],\n",
      "         [-0.1372,  0.8393],\n",
      "         [ 0.1106,  0.5161],\n",
      "         [-0.2461,  0.8542],\n",
      "         [ 0.0403,  0.8657],\n",
      "         [-0.0816,  0.5632],\n",
      "         [ 0.1010,  0.7331],\n",
      "         [ 0.0678,  0.6030],\n",
      "         [ 0.1757,  0.5840],\n",
      "         [-0.3222,  0.6917],\n",
      "         [ 0.0051,  0.7815],\n",
      "         [ 0.0048,  0.7008]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1535,  0.7910],\n",
      "         [ 0.1401,  0.6094],\n",
      "         [ 0.0129,  0.7980],\n",
      "         [ 0.0153,  0.7625],\n",
      "         [ 0.1440,  0.8111],\n",
      "         [-0.0998,  0.7246],\n",
      "         [ 0.0601,  0.6234],\n",
      "         [-0.1754,  0.6987],\n",
      "         [-0.2636,  0.8495],\n",
      "         [-0.0222,  0.7113],\n",
      "         [-0.0949,  0.5731],\n",
      "         [-0.1238,  0.6580]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0585,  0.5943],\n",
      "         [-0.1280,  0.6982],\n",
      "         [-0.2615,  0.7140],\n",
      "         [ 0.1338,  0.6672],\n",
      "         [ 0.1356,  0.7207],\n",
      "         [-0.0961,  0.8540],\n",
      "         [ 0.1041,  0.6005],\n",
      "         [-0.1277,  0.5160],\n",
      "         [ 0.1031,  0.7415],\n",
      "         [-0.0584,  0.5965],\n",
      "         [-0.1801,  0.8596],\n",
      "         [ 0.1874,  0.8392]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.3704,  0.8547],\n",
      "         [ 0.1794,  0.6177],\n",
      "         [ 0.3520,  0.8024],\n",
      "         [-0.0491,  0.7609],\n",
      "         [-0.0579,  0.5921],\n",
      "         [ 0.1051,  0.6819],\n",
      "         [-0.1047,  0.7542],\n",
      "         [-0.1351,  0.7603],\n",
      "         [ 0.1497,  0.8017],\n",
      "         [ 0.2879,  0.7192],\n",
      "         [-0.2947,  0.6457],\n",
      "         [-0.0685,  0.5694]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.2439,  0.8717],\n",
      "         [-0.1003,  0.8098],\n",
      "         [-0.0863,  0.5978],\n",
      "         [-0.1811,  0.7578],\n",
      "         [-0.1933,  0.7929],\n",
      "         [-0.1683,  0.5764],\n",
      "         [ 0.1696,  0.8402],\n",
      "         [ 0.0868,  0.8371],\n",
      "         [-0.0691,  0.6048],\n",
      "         [ 0.3073,  0.5480],\n",
      "         [-0.0845,  0.7097],\n",
      "         [-0.2764,  0.7318]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1724,  0.6221],\n",
      "         [-0.0674,  0.6605],\n",
      "         [ 0.1319,  0.7774],\n",
      "         [ 0.3827,  0.5902],\n",
      "         [ 0.3079,  0.6137],\n",
      "         [ 0.1442,  0.7165],\n",
      "         [ 0.2086,  0.5656],\n",
      "         [-0.0661,  0.7284],\n",
      "         [ 0.0240,  0.5890],\n",
      "         [-0.1002,  0.7461],\n",
      "         [ 0.0453,  0.6124],\n",
      "         [-0.1588,  0.8272]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0228,  0.6362],\n",
      "         [-0.3646,  0.7193],\n",
      "         [ 0.0371,  0.6364],\n",
      "         [-0.1936,  0.6495],\n",
      "         [-0.2912,  0.5703],\n",
      "         [ 0.3286,  0.5782],\n",
      "         [-0.2602,  0.7726],\n",
      "         [ 0.3333,  0.7144],\n",
      "         [ 0.2968,  0.7043],\n",
      "         [ 0.1442,  0.6461],\n",
      "         [-0.2490,  0.7004],\n",
      "         [-0.1007,  0.8374]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.4238,  0.7716],\n",
      "         [-0.1562,  0.5496],\n",
      "         [ 0.1956,  0.7905],\n",
      "         [ 0.0429,  0.7040],\n",
      "         [ 0.1890,  0.6442],\n",
      "         [-0.1261,  0.5730],\n",
      "         [-0.2453,  0.6672],\n",
      "         [ 0.0816,  0.5972],\n",
      "         [ 0.0206,  0.5428],\n",
      "         [ 0.0639,  0.5593],\n",
      "         [-0.1128,  0.6346],\n",
      "         [ 0.1213,  0.6897]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3682,  0.6442],\n",
      "         [-0.0180,  0.8498],\n",
      "         [-0.4264,  0.7216],\n",
      "         [-0.1453,  0.6104],\n",
      "         [-0.1631,  0.7475],\n",
      "         [-0.0633,  0.5842],\n",
      "         [-0.3367,  0.5833],\n",
      "         [-0.1135,  0.9058],\n",
      "         [-0.1700,  0.7891],\n",
      "         [ 0.0070,  0.8090],\n",
      "         [-0.1671,  0.7225],\n",
      "         [ 0.1484,  0.5789]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0072,  0.6598],\n",
      "         [-0.0325,  0.6894],\n",
      "         [ 0.0219,  0.5699],\n",
      "         [-0.2825,  0.6780],\n",
      "         [ 0.2403,  0.5746],\n",
      "         [-0.0597,  0.6886],\n",
      "         [ 0.0460,  0.6988],\n",
      "         [-0.2762,  0.5925],\n",
      "         [-0.0961,  0.9028],\n",
      "         [ 0.2605,  0.8137],\n",
      "         [-0.2352,  0.5991],\n",
      "         [ 0.0859,  0.5825]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3102,  0.7892],\n",
      "         [ 0.0930,  0.6725],\n",
      "         [ 0.0635,  0.7674],\n",
      "         [-0.0993,  0.6499],\n",
      "         [-0.3942,  0.6551],\n",
      "         [-0.0578,  0.6957],\n",
      "         [-0.0992,  0.5661],\n",
      "         [ 0.0947,  0.7894],\n",
      "         [-0.0577,  0.7653],\n",
      "         [-0.1368,  0.6371],\n",
      "         [ 0.1383,  0.6651],\n",
      "         [ 0.0961,  0.7375]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3221,  0.8602],\n",
      "         [ 0.1496,  0.7939],\n",
      "         [ 0.0295,  0.6209],\n",
      "         [-0.1399,  0.6151],\n",
      "         [-0.0785,  0.6126],\n",
      "         [-0.3159,  0.7803],\n",
      "         [-0.0340,  0.7590],\n",
      "         [-0.2671,  0.7604],\n",
      "         [ 0.1700,  0.6880],\n",
      "         [ 0.0749,  0.6021],\n",
      "         [-0.3116,  0.7092],\n",
      "         [ 0.3631,  0.8670]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.3000,  0.8112],\n",
      "         [ 0.1774,  0.8028],\n",
      "         [-0.1626,  0.7287],\n",
      "         [-0.1324,  0.6641],\n",
      "         [ 0.2371,  0.7553],\n",
      "         [-0.1783,  0.5642],\n",
      "         [-0.0603,  0.8205],\n",
      "         [-0.0663,  0.5559],\n",
      "         [ 0.2322,  0.8549],\n",
      "         [-0.2152,  0.7968],\n",
      "         [-0.1226,  0.7223],\n",
      "         [ 0.3707,  0.8090]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0107,  0.6500],\n",
      "         [-0.1703,  0.6800],\n",
      "         [-0.2093,  0.5799],\n",
      "         [ 0.1089,  0.6163],\n",
      "         [-0.1101,  0.5808],\n",
      "         [ 0.3440,  0.6563],\n",
      "         [-0.1993,  0.5545],\n",
      "         [ 0.2232,  0.6731],\n",
      "         [-0.0091,  0.6331],\n",
      "         [-0.0224,  0.7839],\n",
      "         [-0.0353,  0.8119],\n",
      "         [ 0.3371,  0.7674]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2516,  0.6551],\n",
      "         [-0.1210,  0.7473],\n",
      "         [-0.0412,  0.8346],\n",
      "         [ 0.2322,  0.7278],\n",
      "         [-0.1656,  0.6225],\n",
      "         [-0.1901,  0.6940],\n",
      "         [-0.1256,  0.7575],\n",
      "         [ 0.1271,  0.6212],\n",
      "         [-0.1389,  0.6243],\n",
      "         [ 0.1310,  0.6600],\n",
      "         [-0.1747,  0.9116],\n",
      "         [ 0.0818,  0.6252]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0574,  0.7789],\n",
      "         [ 0.0460,  0.6133],\n",
      "         [-0.2689,  0.6351],\n",
      "         [-0.1102,  0.6071],\n",
      "         [ 0.1079,  0.8123],\n",
      "         [ 0.3872,  0.7787],\n",
      "         [-0.0357,  0.7362],\n",
      "         [ 0.1087,  0.7216],\n",
      "         [ 0.0239,  0.7867],\n",
      "         [ 0.2708,  0.8615],\n",
      "         [-0.0179,  0.7278],\n",
      "         [ 0.3107,  0.7080]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0695,  0.5856],\n",
      "         [ 0.1332,  0.6104],\n",
      "         [ 0.3829,  0.7576],\n",
      "         [-0.1375,  0.6629],\n",
      "         [-0.2718,  0.6743],\n",
      "         [ 0.1621,  0.5601],\n",
      "         [ 0.0085,  0.5535],\n",
      "         [-0.1661,  0.5418],\n",
      "         [-0.0766,  0.6795],\n",
      "         [-0.0137,  0.7845],\n",
      "         [ 0.1321,  0.6397],\n",
      "         [-0.1281,  0.6544]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0152,  0.8984],\n",
      "         [ 0.0796,  0.7879],\n",
      "         [ 0.1822,  0.7593],\n",
      "         [-0.0960,  0.6489],\n",
      "         [-0.3597,  0.5946],\n",
      "         [-0.1397,  0.5805],\n",
      "         [ 0.1908,  0.5727],\n",
      "         [-0.2250,  0.8222],\n",
      "         [ 0.1521,  0.7356],\n",
      "         [ 0.2293,  0.7041],\n",
      "         [ 0.2364,  0.5699],\n",
      "         [-0.1428,  0.5501]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1645,  0.6706],\n",
      "         [-0.0396,  0.5949],\n",
      "         [-0.0250,  0.7524],\n",
      "         [ 0.2273,  0.6967],\n",
      "         [ 0.0476,  0.7788],\n",
      "         [ 0.1591,  0.6311],\n",
      "         [ 0.0893,  0.7569],\n",
      "         [-0.1273,  0.8950],\n",
      "         [ 0.0025,  0.5629],\n",
      "         [-0.4598,  0.7422],\n",
      "         [ 0.0860,  0.8052],\n",
      "         [-0.0995,  0.6217]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0129,  0.5534],\n",
      "         [-0.0290,  0.8039],\n",
      "         [ 0.2713,  0.6842],\n",
      "         [ 0.2041,  0.6488],\n",
      "         [ 0.0633,  0.5634],\n",
      "         [ 0.1583,  0.6421],\n",
      "         [-0.1215,  0.6252],\n",
      "         [ 0.0679,  0.5809],\n",
      "         [-0.1150,  0.7760],\n",
      "         [-0.4461,  0.8123],\n",
      "         [ 0.2046,  0.6553],\n",
      "         [ 0.0019,  0.6211]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0506,  0.6911],\n",
      "         [-0.0882,  0.7732],\n",
      "         [-0.1216,  0.7650],\n",
      "         [-0.2659,  0.7934],\n",
      "         [-0.0819,  0.7131],\n",
      "         [-0.1150,  0.5909],\n",
      "         [ 0.2259,  0.8631],\n",
      "         [-0.0824,  0.6174],\n",
      "         [ 0.0513,  0.8382],\n",
      "         [ 0.1006,  0.5687],\n",
      "         [-0.2287,  0.6474],\n",
      "         [ 0.0981,  0.5839]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0072,  0.6451],\n",
      "         [ 0.2244,  0.6088],\n",
      "         [-0.1147,  0.6586],\n",
      "         [-0.0236,  0.7240],\n",
      "         [-0.1266,  0.7302],\n",
      "         [-0.1410,  0.7593],\n",
      "         [-0.2410,  0.6638],\n",
      "         [-0.4030,  0.6948],\n",
      "         [-0.1805,  0.7317],\n",
      "         [ 0.2064,  0.6779],\n",
      "         [ 0.0238,  0.6890],\n",
      "         [ 0.0138,  0.5921]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0514,  0.5538],\n",
      "         [ 0.3902,  0.8192],\n",
      "         [ 0.1090,  0.6321],\n",
      "         [-0.2907,  0.6967],\n",
      "         [ 0.0596,  0.8007],\n",
      "         [ 0.2251,  0.8740],\n",
      "         [-0.2323,  0.7803],\n",
      "         [-0.0959,  0.7632],\n",
      "         [-0.1992,  0.6517],\n",
      "         [ 0.1813,  0.8123],\n",
      "         [ 0.1028,  0.6029],\n",
      "         [-0.1293,  0.5451]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.1693,  0.7232],\n",
      "         [-0.2552,  0.5600],\n",
      "         [ 0.2503,  0.5918],\n",
      "         [-0.1756,  0.7097],\n",
      "         [-0.2202,  0.6529],\n",
      "         [ 0.2143,  0.6146],\n",
      "         [-0.0204,  0.5631],\n",
      "         [ 0.3626,  0.6931],\n",
      "         [-0.1462,  0.6322],\n",
      "         [-0.2041,  0.8663],\n",
      "         [-0.2267,  0.7418],\n",
      "         [ 0.0010,  0.7124]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[-0.0746,  0.7990],\n",
      "         [-0.0410,  0.5496],\n",
      "         [ 0.0903,  0.8344],\n",
      "         [-0.1140,  0.6896],\n",
      "         [-0.0373,  0.8928],\n",
      "         [-0.1196,  0.7384],\n",
      "         [ 0.2391,  0.7791],\n",
      "         [ 0.1815,  0.7829],\n",
      "         [ 0.0184,  0.7695],\n",
      "         [ 0.0151,  0.6488],\n",
      "         [-0.1636,  0.8713],\n",
      "         [-0.1204,  0.5513]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.2590,  0.6184],\n",
      "         [-0.1356,  0.5987],\n",
      "         [ 0.0225,  0.6308],\n",
      "         [ 0.2837,  0.7324],\n",
      "         [ 0.1815,  0.5703],\n",
      "         [ 0.1650,  0.6532],\n",
      "         [ 0.0311,  0.7984],\n",
      "         [ 0.2583,  0.7064],\n",
      "         [-0.1471,  0.7401],\n",
      "         [ 0.4416,  0.8379],\n",
      "         [-0.1197,  0.7940],\n",
      "         [ 0.2427,  0.7363]]], grad_fn=<CopySlices>)\n",
      "distrib_pars = tensor([[[ 0.0171,  0.7067],\n",
      "         [-0.3323,  0.6400],\n",
      "         [ 0.1962,  0.4973],\n",
      "         [-0.3674,  0.5846],\n",
      "         [ 0.0426,  0.6339],\n",
      "         [ 0.2084,  0.5809],\n",
      "         [-0.2154,  0.9481],\n",
      "         [ 0.0084,  0.7184],\n",
      "         [-0.3473,  0.6377],\n",
      "         [ 0.0474,  0.7557],\n",
      "         [-0.2287,  0.7881],\n",
      "         [ 0.0764,  0.6658]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "hidden_size=12\n",
    "model = DeepAR(batch_size=1, input_size=time_series_df.shape[1], hidden_size=hidden_size)\n",
    "for batch_num, X in enumerate(training_dataloader):\n",
    "    distrib_pars = model(X)\n",
    "    print(f'distrib_pars = {distrib_pars}')\n",
    "    # #print(f'shape of yhat = {y_hat.shape}; shape of y = {y.shape}')\n",
    "    # loss = loss_function(y_hat, y.squeeze())\n",
    "    # mean_loss += loss.item()\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    # batches_count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 3, 1])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 3, 5])\n",
    "b = np.flip(a)\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}